# Numerical-Optimization-for-Machine-Learning

**Implementation for different optimizations protocols: Batch Gradient Descent, Mini-Batch Gradient Descent, Stochastic Gradient Descent, Momentum Gradient Descent, NAG Algorithm, Adagrad Algorithm, RMS-Prop Algorithm, Adam Algorithm.**
